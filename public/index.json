[
{
	"uri": "http://localhost:1313/3-accessibilitytoinstances/3.1-public-instance/",
	"title": "Connect, Install, and Deploy",
	"tags": [],
	"description": "",
	"content": "Detailed Guide to Commands on MobaXterm In this section, you will execute commands to connect to the ors-ec2 server, then install the environment and deploy the Node.js backend application.\nNote: The commands must be executed sequentially. Ensure you have completed the previous step before moving on to the next.\n1. Connect to the EC2 Instance This is the first step, connecting from your computer to the ors-ec2 server in the Public Subnet.\nOpen MobaXterm and create a new SSH session. Remote host: Enter the Public IPv4 address of ors-ec2 (you can get this from the EC2 Dashboard). Specify username: ec2-user. Use private key: Select the ors-keypair.pem file you downloaded. Set permissions for the key file (if using Terminal on macOS/Linux): Before connecting, you need to run this command on your personal computer to secure the key file: chmod 400 ors-keypair.pem Setting up the SSH session in MobaXterm 2. Install the Environment on the Server Once successfully connected to the server, install the necessary tools.\nUpdate the system:\nsudo yum update -y Updating system packages Install Git:\nsudo yum install -y git Clone the project source code from GitHub:\ngit clone https://github.com/tuilatri/online-restaurant-system.git Cloning the project Move into the backend directory:\ncd online-restaurant-system/backend Install Node.js and npm:\nsudo dnf install -y nodejs Installing Node.js Check the versions to confirm successful installation:\nnode -v npm -v 3. Install and Configure the Application Install the project\u0026rsquo;s dependencies:\nnpm install Installing npm packages Move into the src directory and create the environment variable configuration file:\ncd src nano .env Enter the database connection information: In the nano editor, paste the following content and replace it with your information.\nDB_HOST=\u0026#39;your-rds-endpoint\u0026#39; DB_USER=\u0026#39;admin\u0026#39; DB_PASSWORD=\u0026#39;your-db-password\u0026#39; DB_DATABASE=\u0026#39;ors\u0026#39; DB_PORT=3306 Configuring the .env file Save and exit nano:\nPress Ctrl + O Press Enter to confirm the file name. Press Ctrl + X to exit. 4. Launch and Test the Backend Launch the application:\nnode createAdmin.js node server.js Backend application running on port 5000 Test the application\u0026rsquo;s operation directly on the server: Open a new terminal window in MobaXterm and connect to the same EC2 instance again, then use the curl command to test.\ncurl http://127.0.0.1:5000/api If you receive the response Welcome to Dining Verse Backend API!, it means the application has started successfully!\n5. Troubleshooting Guide If you update the code on GitHub but the changes do not appear on the web, follow these steps on the server:\nMove into the backend directory:\ncd online-restaurant-system/backend Pull the latest code:\ngit pull origin main Find the running Node.js process:\nps aux | grep node Stop the old process using its PID:\nkill -9 \u0026lt;PID\u0026gt; Practical example:\n[ec2-user@ip-10-0-144-101 backend]$ ps aux | grep node\rec2-user 3117 0.0 6.6 1127836 64896 pts/1 Sl+ 10:15 0:00 node server.js\r[ec2-user@ip-10-0-144-101 backend]$ kill -9 3117 Restart the application:\nnpm run start "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.1-createvpc/",
	"title": "Create VPC and Subnets",
	"tags": [],
	"description": "",
	"content": "Create the Network Environment (VPC) ‚ÑπÔ∏è Objective\nCreate an isolated virtual network environment (VPC) in AWS for the restaurant project. Use the \u0026ldquo;VPC and more\u0026rdquo; wizard to automatically set up the necessary network components, including Public Subnets, Private Subnets, an Internet Gateway, and Route Tables. üîí Steps to Follow\n1. Access the VPC Service From the AWS Management Console, search for the VPC service. Select VPC from the search results to go to the VPC management page. Search for the VPC service 2. Start Creating the VPC In the VPC Dashboard, on the left menu, select Your VPCs. Click the Create VPC button in the upper right corner. Click the Create VPC button 3. Configure VPC Parameters On the Create VPC page, under the Resources to create section, make sure you have selected VPC and more to use the automatic creation wizard.\nDetailed configuration:\nName tag auto-generation: ors-vpc IPv4 CIDR block: Leave the default 10.0.0.0/16. Number of Availability Zones (AZs): 2 Number of Public subnets: 2 Number of Private subnets: 2 NAT gateways: None (To save costs for this workshop). VPC endpoints: None Configure VPC and more for the project Explanation: We are creating 2 Public Subnets to place resources that need internet access, like the Load Balancer, and 2 Private Subnets to protect sensitive resources like the EC2 backend and RDS database. Spanning across 2 AZs helps increase the system\u0026rsquo;s High Availability.\n4. Finalize and Create the VPC After filling in all the information, scroll down and click on Create VPC. Finalize and create the VPC 5. Check the Result The process of creating the network resources may take a few minutes. Once completed, you will see a success message. Click on View VPC to review the resources that have been created. VPC creation success message You will be redirected to the list of VPCs. Here, the newly created ors-vpc will have the status Available, ready for the next configuration steps. Check the VPC in the list "
},
{
	"uri": "http://localhost:1313/",
	"title": "Deploying an Online Restaurant Project on AWS",
	"tags": [],
	"description": "",
	"content": "Deploying a Full-Stack Online Restaurant Project on AWS Overview In this workshop, you will be guided step-by-step to deploy a complete online restaurant application on the Amazon Web Services (AWS) platform. The project includes a frontend built with HTML, CSS, and JavaScript, along with a powerful backend using Node.js (Express) and a MySQL database (RDS), creating a scalable, secure, and high-performance system.\nTechnologies and Services Used ‚ÑπÔ∏è The goal of the workshop is to build a professional cloud infrastructure that is fault-tolerant and auto-scaling to meet user traffic demands.\nüí° The main AWS services used are:\nVPC (Virtual Private Cloud): Create a separate and secure network environment on AWS, including Public Subnets for resources that need internet access and Private Subnets to protect the database. EC2 (Elastic Compute Cloud): Where the Node.js backend application is deployed and run. AMI \u0026amp; Launch Templates: Create a \u0026ldquo;template\u0026rdquo; for the server, helping to automate the creation of new EC2 instances uniformly. Application Load Balancer (ALB): Distribute traffic to multiple EC2 instances, increasing the application\u0026rsquo;s availability and load-handling capacity. Auto Scaling Group (ASG): Automatically adjust the number of EC2 instances based on traffic, ensuring stable performance and cost optimization. RDS (Relational Database Service): Provide a fully managed MySQL database, simplifying installation, operation, and backup. S3 (Simple Storage Service): Store and serve the frontend\u0026rsquo;s static resources (HTML, CSS, JavaScript, images). CloudFront: A Content Delivery Network (CDN) service that helps speed up page load times for users globally and secures both the frontend and backend. Architecture and Scope ‚ÑπÔ∏è The project is clearly separated into two parts: Frontend (user interface) and Backend (processing system), deployed independently but communicating closely with each other via API.\nBackend (Server-side)\nThe Node.js application is deployed on EC2 instances within an Auto Scaling Group. The Application Load Balancer will receive requests from users and forward them to the active EC2 instances. The RDS MySQL database is placed in a Private Subnet, only allowing access from EC2 instances to ensure maximum security. A CloudFront distribution is configured to point to the ALB, providing a layer of protection and acceleration for the API endpoints. üîí Frontend (Client-side)\nThe entire frontend source code (static files) is uploaded to an S3 bucket. This S3 bucket is configured to function as a static website. Another CloudFront distribution is set up to serve content from the S3 bucket. The use of Origin Access Identity (OAI) ensures that users can only access the frontend through CloudFront, preventing direct access to the S3 bucket. üí° Let\u0026rsquo;s start building a powerful and professional infrastructure for your application in the following sections!\n"
},
{
	"uri": "http://localhost:1313/1-introduce/",
	"title": "Introduction and Architectural Overview",
	"tags": [],
	"description": "",
	"content": "Architectural Overview In this workshop, we will deploy a complete online restaurant application to the AWS environment. The architecture is designed to ensure High Availability, Scalability, and Security by using core AWS services.\nBelow is the overall architectural diagram of the project we will build:\nAWS Services Used Here is a list of the main services and their roles in this project:\nNetworking \u0026amp; Security Amazon VPC (Virtual Private Cloud): This is the networking foundation for the entire project. We will create a VPC named ors-vpc to establish an isolated network environment, allowing complete control over the IP range, subnets, and route tables.\nPublic \u0026amp; Private Subnets:\nPublic Subnets: Used for resources that need to be accessed from the internet, such as the Application Load Balancer. Private Subnets: Used to house sensitive resources like the backend EC2 servers and the RDS database, preventing direct access from the internet to enhance security. Security Groups: Act as a virtual firewall to control inbound and outbound traffic.\nors-sg: For the Web Server, allowing traffic from the internet on ports 80 (HTTP), 443 (HTTPS), and 5000 (Node.js App), as well as port 22 (SSH) from your IP for administration. ors-db-sg: For the Database, only allowing connections from servers within the ors-sg Security Group on port 3306 (MySQL), ensuring the database is completely protected. Database Amazon RDS (Relational Database Service): Provides a fully managed MySQL database. We will create an instance named ors-db in a Private Subnet, which simplifies operations, backups, and ensures security. Compute \u0026amp; Scalability Amazon EC2 (Elastic Compute Cloud): Provides virtual servers to run the Node.js backend application. These servers will be placed in a Private Subnet.\nAMI (Amazon Machine Image) \u0026amp; Launch Template:\nWe will configure a complete EC2 instance (installing Node.js, Git, etc.) and then create an AMI named ors-ami. This AMI is then used in a Launch Template named ors-launch-template to serve as a \u0026ldquo;blueprint\u0026rdquo; for creating new servers automatically and consistently. Application Load Balancer (ALB): Automatically distributes incoming traffic from users to multiple backend EC2 servers via a Target Group (ors-target-group). The ALB also performs health checks to ensure requests are only sent to healthy instances.\nAuto Scaling Group (ASG): Automatically adjusts the number of backend EC2 servers based on the actual load (e.g., number of requests per minute). When traffic increases, the ASG will automatically add new servers and will remove them when traffic decreases, helping to optimize costs and ensure performance.\nStorage \u0026amp; Content Delivery Amazon S3 (Simple Storage Service): Used to store the entire frontend source code (HTML, CSS, JavaScript, images) in a bucket named ors-fe. This bucket will be configured to function as a static website.\nAmazon CloudFront: Is a Content Delivery Network (CDN) service that helps speed up and secure both the frontend and backend.\nFrontend Distribution: Distributes static content from S3. We will use Origin Access Identity (OAI) to lock down the S3 bucket, forcing users to access the website through CloudFront, thereby enhancing security. Backend Distribution: Provides a secure HTTPS endpoint for the API, acting as a proxy and forwarding requests to the Application Load Balancer. "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.2-modifysubnet/",
	"title": "Modify Public Subnet",
	"tags": [],
	"description": "",
	"content": "Configure Auto-assign Public IP for Public Subnets ‚ÑπÔ∏è Objective\nEnable the feature to automatically assign a Public IP address to EC2 instances launched in the Public Subnets. This is a mandatory step so that we can access and configure the initial server from the Internet via SSH. üîí Steps to Follow\n1. Access the Subnet Management Page From the VPC Dashboard interface, select Subnets from the left menu to view the list of all subnets belonging to your ors-vpc. List of Subnets for ors-vpc 2. Edit the First Public Subnet Identify and select one of the two created Public Subnets (e.g., ors-vpc-subnet-public1-ap-southeast-1a). Click the Actions button and select Edit subnet settings. Select Edit subnet settings 3. Enable the Auto-assign IP Feature On the Edit subnet settings page, find the Auto-assign IP settings section. Check the box for Enable auto-assign public IPv4 address. Scroll down and click Save to apply the changes. Enable the Auto-assign Public IP feature When this feature is enabled, any EC2 instance launched in this subnet will automatically receive a public IP address, allowing it to communicate with the Internet.\n4. Repeat for the Remaining Public Subnet Repeat steps 2 and 3 for the second Public Subnet (e.g., ors-vpc-subnet-public2-ap-southeast-1b). This ensures that our system can operate uniformly across both Availability Zones, maintaining high availability. Complete the configuration for both Public Subnets "
},
{
	"uri": "http://localhost:1313/2-prerequiste/",
	"title": "Prerequisites and Infrastructure Setup",
	"tags": [],
	"description": "",
	"content": "This page provides an overview of the necessary steps to set up the complete infrastructure for the restaurant project on AWS. Each section in the list below will link to a detailed guide.\nPlease follow the steps below sequentially. Setting them up in the wrong order can lead to configuration errors and prevent components from communicating with each other.\nMain Content of This Chapter Configure the Network Environment (VPC)\nCreate VPC and Subnets Modify Public Subnet Set Up Security Layers (Security Group)\nCreate Security Groups for Web Server and Database Initialize Server and Database\nCreate an initial EC2 Instance for configuration Create an RDS MySQL Database (Note: The RDS creation step has been added here to ensure a seamless workshop flow) Prepare for Automatic Scaling (Automation)\nCreate an Amazon Machine Image (AMI) from the configured EC2 Create a Launch Template for the Auto Scaling Group Set Up Load Balancing\nCreate a Target Group Create an Application Load Balancer (ALB) Configure Auto Scaling\nCreate an Auto Scaling Group (ASG) Storage and Content Delivery (CDN)\nCreate an S3 Bucket for the Frontend Create CloudFront for the Backend (pointing to ALB) Create CloudFront for the Frontend (pointing to S3) "
},
{
	"uri": "http://localhost:1313/3-accessibilitytoinstances/",
	"title": "Connecting and Deploying the Application",
	"tags": [],
	"description": "",
	"content": "After having built the entire infrastructure on AWS, the next step is to connect to the EC2 instance, install the necessary environment, and deploy the backend application\u0026rsquo;s source code.\nSince our initial ors-ec2 server is placed in a Public Subnet and has been assigned a public IP, we can connect directly to it from our personal computer using SSH to perform the setup tasks.\nThe process in this chapter will include:\nConnecting to the EC2 instance using the created .pem file. Installing necessary tools like Git, Node.js. Downloading the project\u0026rsquo;s source code from GitHub to the server. Configuring environment variables to connect to the RDS database. Running the backend application and testing its operation. In this chapter, MobaXterm will be the primary SSH client tool used on Windows to make connections and run commands. You can also use other tools like Terminal (macOS/Linux) or PuTTY.\n"
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.3-createsg/",
	"title": "Create Security Groups",
	"tags": [],
	"description": "",
	"content": "Create Security Layers (Security Group) ‚ÑπÔ∏è Objective\nA Security Group acts as a virtual firewall at the instance level to control inbound and outbound traffic. In this section, we will create 2 separate Security Groups for the two core components in our architecture: Web Server (ors-sg): Receives traffic from users and allows administrators to connect. Database (ors-db-sg): Only allows connections from the Web Server and administrators, ensuring absolute data security. üîí Steps to Follow\n1. Create Security Group for the Web Server (ors-sg) This is the security layer for the EC2 instances that will run the Node.js backend application.\nStep 1: Start creating a Security Group\nFrom the VPC Dashboard interface, select Security Groups from the left menu. Click on Create security group. Create a new Security Group Step 2: Configure basic information\nSecurity group name: ors-sg Description: Security group for Online Restaurant Web Server VPC: Select the ors-vpc VPC created in the previous step. Basic information for the Web Server SG Step 3: Set up Inbound Rules\nIn the Inbound rules section, click Add rule and configure the following 4 rules: Type Protocol Port range Source Description SSH TCP 22 My IP Allows you to connect via SSH from your current IP to manage the server. HTTP TCP 80 Anywhere-IPv4 Allows users to access the web server via HTTP. HTTPS TCP 443 Anywhere-IPv4 Allows users to access securely via HTTPS. Custom TCP TCP 5000 Anywhere-IPv4 Opens the port for the Node.js application (for testing and load balancing). Configure Inbound Rules for the Web Server SG When selecting My IP as the Source, AWS will automatically fill in your public IP address. This enhances security by only allowing administrators to access from a trusted location.\nStep 4: Scroll to the bottom and click Create security group. 2. Create Security Group for the Database (ors-db-sg) This security layer is designed to \u0026ldquo;lock down\u0026rdquo; the database, allowing only absolutely necessary connections.\nStep 1: Configure basic information\nClick Create security group again. Security group name: ors-db-sg Description: Security group for Online Restaurant Database VPC: Select the ors-vpc VPC. Basic information for the Database SG Step 2: Set up Inbound Rules\nClick Add rule and configure the following 2 rules: Type Protocol Port range Source Description MYSQL/Aurora TCP 3306 Custom -\u0026gt; ors-sg Important: Only allows web servers (belonging to ors-sg) to connect to the DB. MYSQL/Aurora TCP 3306 My IP Allows you to connect to the DB from your personal machine for management (e.g., using MySQL Workbench). Important Security Principle: By selecting another Security Group (ors-sg) as the Source, we create a dynamic rule. Any server belonging to ors-sg can connect to the database without needing to specify a particular IP address. This is the best practice for security in a cloud environment.\nConfigure Inbound Rules for the Database SG Step 3: Click Create security group. After completion, you will have 2 correctly configured Security Groups ready to protect your project\u0026rsquo;s resources.\n"
},
{
	"uri": "http://localhost:1313/4-cleanup/",
	"title": "Clean up Resources",
	"tags": [],
	"description": "",
	"content": "To avoid incurring unwanted costs, it\u0026rsquo;s important to delete all the AWS resources that were created during this workshop.\nThe deletion order is very important! Please follow the steps below sequentially. Deleting resources in the wrong order (e.g., deleting the VPC before the ALB) will cause errors because the resources are still dependent on each other.\n1. Delete the Auto Scaling Group (ors-asg) This is the most important first step. Otherwise, the ASG will automatically recreate the EC2 instances after you delete them.\nNavigate to the EC2 service -\u0026gt; Auto Scaling Groups. Select ors-asg. Click Delete. Type delete in the confirmation box and click Delete. This action will also automatically terminate the EC2 instances managed by the ASG. 2. Delete the Application Load Balancer (ors-alb) In the EC2 Dashboard, go to Load Balancers. Select ors-alb. Click Actions -\u0026gt; Delete load balancer. Type confirm in the confirmation box and click Delete. 3. Delete the Target Group (ors-target-group) In the EC2 Dashboard, go to Target Groups. Select ors-target-group. Click Actions -\u0026gt; Delete. Confirm the deletion. 4. Delete the EC2 Instance and related resources Manually Terminate EC2 Instance: Go to Instances. Select ors-ec2 (the instance you created initially). Click Instance state -\u0026gt; Terminate instance. Deregister AMI: Go to AMIs (under the Images section). Select ors-ami. Click Actions -\u0026gt; Deregister AMI. Delete Launch Template: Go to Launch Templates. Select ors-launch-template. Click Actions -\u0026gt; Delete template. Delete Key Pair: Go to Key Pairs (under the Network \u0026amp; Security section). Select ors-keypair. Click Actions -\u0026gt; Delete. 5. Delete the RDS Database (ors-db) Navigate to the RDS service -\u0026gt; Databases. Select ors-db. Click Actions -\u0026gt; Delete. Uncheck the Create final snapshot? box. Check the I acknowledge... box. Type delete me in the confirmation box and click Delete. The RDS database deletion process may take a few minutes.\n6. Delete CloudFront Distributions You need to repeat this process for both distributions you created (one for the backend and one for the frontend).\nNavigate to the CloudFront service. Select a distribution. Click Disable. Wait a few minutes until the status updates (the Last modified column shows a value). Once it is disabled, select the distribution again and click Delete. 7. Delete the S3 Bucket (ors-fe) Navigate to the S3 service. Select the ors-fe bucket. Click the Empty button. Type permanently delete in the confirmation box and click Empty. After the bucket is empty, go back to the bucket list, select ors-fe again, and click Delete. Type the bucket name in the confirmation box and click Delete bucket. 8. Delete the VPC (ors-vpc) This is the final step, which deletes the entire network environment.\nNavigate to the VPC service -\u0026gt; Your VPCs. Select ors-vpc. Click Actions -\u0026gt; Delete VPC. A window will appear, listing all related resources that will be deleted along with it (Subnets, Route Tables, Security Groups, etc.). Type delete vpc in the confirmation box and click Delete. "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.4-createec2/",
	"title": "Create the Initial EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Launch an Initial EC2 Instance for Configuration ‚ÑπÔ∏è Objective\nLaunch a first virtual server (EC2 Instance), named ors-ec2. This server will be placed in a Public Subnet so that we can access it to install the environment (Node.js, Git, etc.) and configure the application. Once completed, this instance will be used as a \u0026ldquo;blueprint\u0026rdquo; to create an AMI (Amazon Machine Image) for automatic scaling later on. üîí Steps to Follow\n1. Start Launching the Instance In the AWS Management Console, find and select the EC2 service. From the EC2 Dashboard, click the Launch instance button. Start Launch Instance from the EC2 Dashboard 2. Name the Instance and Choose an AMI Name: ors-ec2 Application and OS Images (Amazon Machine Image): Choose Amazon Linux. This operating system is optimized for AWS and is highly compatible with the tools we will be using. Name the instance and select an Amazon Machine Image 3. Choose an Instance Type Instance type: Select t2.micro. This instance type is part of the AWS Free Tier, making it suitable for learning and development. 4. Create a Key Pair for Access This is an extremely important step to be able to connect to the server via SSH. In the Key pair (login) section, click on Create new key pair. Key pair name: ors-keypair Key pair type: RSA Private key file format: .pem (for use with MobaXterm or Terminal on macOS/Linux). Click Create key pair, and the browser will automatically download the ors-keypair.pem file. IMPORTANT: Store this .pem file in a safe place and never share it. You cannot download this file a second time. If you lose it, you will lose access to your EC2 instance.\nCreate a new Key Pair for secure access 5. Configure Network Settings Click the Edit button in the Network settings section. VPC: Select the ors-vpc you created. Subnet: Choose one of the two configured Public Subnets (e.g., ors-vpc-subnet-public1-ap-southeast-1a). Auto-assign public IP: Enable. (This is why we configured the subnet in step 2.2). Firewall (security groups): Choose Select existing security group. From the Common security groups list, select ors-sg which we created in step 2.3. Configure detailed network settings for the EC2 instance 6. Launch and Check the Instance Review the configured information in the Summary panel on the right.\nClick Launch instance.\nAfter a successful launch, you can click View all instances to see your ors-ec2 server.\nWait a few minutes until the Status check column changes to 2/2 checks passed. At this point, your server is ready to be connected to.\nCheck the EC2 instance in the list "
},
{
	"uri": "http://localhost:1313/5-conclusion/",
	"title": "Conclusion and Next Steps",
	"tags": [],
	"description": "",
	"content": "Congratulations on completing the workshop!\nYou have successfully built and deployed a modern, scalable, highly available, and secure full-stack web application architecture on the AWS platform. This is not just a simple exercise but an incredibly solid foundation that simulates how real-world systems are built in the cloud.\nBy combining services like VPC, EC2, Auto Scaling Group, ALB, RDS, S3, and CloudFront, you have created a robust system capable of handling variable traffic loads in a real-world scenario.\nUpgrading and Extending the Project The current architecture is an excellent starting point. Below are potential improvement paths you can explore to make this system even better, more automated, and more professional.\n1. Automate Deployment with a CI/CD Pipeline Problem: Currently, the code update process is manual (SSH into the server, git pull, kill the old process, npm start). This process is time-consuming, error-prone, and not suitable for a professional environment. Solution: Build a CI/CD (Continuous Integration/Continuous Deployment) pipeline using services like AWS CodePipeline, AWS CodeBuild, and AWS CodeDeploy. With CI/CD, every time you push new code to GitHub, the system will automatically build, test, and deploy the new version to the EC2 instances without any manual intervention. 2. Manage Infrastructure with Code (Infrastructure as Code - IaC) Problem: Setting up the entire infrastructure manually through the AWS Console (also known as ClickOps) is difficult to reproduce accurately and lacks version control capabilities. Solution: Learn to use IaC tools like AWS CloudFormation or Terraform. You can define the entire architecture (VPC, EC2, ALB, S3, etc.) in code files. This allows you to recreate, update, or delete the entire environment with just a few commands, ensuring consistency and automation. 3. Containerize the Application with Docker and ECS Problem: Installing the environment directly on EC2 can lead to inconsistencies between the development and production environments. Solution: \u0026ldquo;Package\u0026rdquo; your Node.js application into a Docker container. Then, instead of running it on EC2, you can deploy this container to Amazon ECS (Elastic Container Service). ECS will help you manage, scale, and operate containers more easily and efficiently. 4. Use a Custom Domain with Amazon Route 53 Problem: Users are accessing the application through the default, long, and hard-to-remember CloudFront domain names. Solution: Use Amazon Route 53, AWS\u0026rsquo;s DNS service, to register a custom domain (e.g., my-cool-restaurant.com) and point it to your CloudFront distributions. You can also use AWS Certificate Manager (ACM) to issue free SSL/TLS certificates for your domain. 5. Monitoring, Logging, and Alerting with Amazon CloudWatch Problem: How do you know if the application is running well or encountering errors? When should Auto Scaling be triggered? Solution: Integrate more deeply with Amazon CloudWatch. You can: CloudWatch Logs: Collect logs from the Node.js application on EC2 for debugging. CloudWatch Metrics: Monitor key performance indicators like EC2 CPU Utilization and ALB Request Count. CloudWatch Alarms: Set up automatic alerts to send you an email when an incident occurs (e.g., high CPU usage, website is unreachable). 6. Enhance Security with AWS WAF Problem: The application could be attacked by common web vulnerabilities like SQL injection or cross-site scripting (XSS). Solution: Integrate AWS WAF (Web Application Firewall) with CloudFront. WAF helps protect your application by filtering and blocking malicious traffic based on rules you define. "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.5-createrds/",
	"title": "Create RDS MySQL Database",
	"tags": [],
	"description": "",
	"content": "Initialize the Database with Amazon RDS ‚ÑπÔ∏è Objective\nCreate a managed MySQL database using the Amazon RDS service. Place this database within the created VPC (ors-vpc) network environment and protect it with a Security Group (ors-db-sg). Use the Free Tier to save costs during this hands-on workshop. üîí Steps to Follow\n1. Access the RDS Service From the AWS Management Console interface, search for and select the RDS service. Search for the RDS service 2. Start Creating the Database In the RDS Dashboard, click the Create database button. Click Create database 3. Configure Engine and Template Choose a database creation method: Select Standard create. Engine options: Select MySQL. Templates: Select Production. Choosing Free tier will automatically limit the configuration options (e.g., you can only select a Single DB instance) to ensure you do not incur unexpected costs.\nSelect Standard create, MySQL, and Free Tier 4. Configure Settings DB instance identifier: ors-db Master username: admin Master password: Enter your password (e.g., 0812-haminhtri). Confirm password: Re-enter your password. Configure login credentials for the Database 5. Configure Connectivity This is a crucial step to place the database in the correct network environment.\nVirtual private cloud (VPC): Select ors-vpc. DB Subnet Group: Leave the default; AWS will automatically create a new Subnet Group suitable for your VPC. Public access: Select Yes. VPC security group (firewall): Select Choose existing. Existing VPC security groups: Keep the default Security Group and select ors-db-sg. Configure network connectivity for RDS 6. Configure Additional Configuration Expand the Additional configuration section. Initial database name: ors This is the initial schema name that the application will use. Set the initial schema name 7. Finalize, Create, and Check Scroll to the bottom and click Create database. The database initialization process can take 5 to 10 minutes. Please wait until the Status column changes to Available. Wait for the Database to be created Once completed, click on the newly created ors-db instance. In the Connectivity \u0026amp; security tab, find and copy the Endpoint value. This is the address used to connect to your database. Get the Endpoint information for connection "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.6-createami/",
	"title": "Create Amazon Machine Image (AMI)",
	"tags": [],
	"description": "",
	"content": "Create an AMI from the Configured EC2 Instance ‚ÑπÔ∏è Objective\nAn Amazon Machine Image (AMI) is a \u0026ldquo;snapshot\u0026rdquo; or a complete backup of an EC2 instance, including the operating system, installed software, and all configurations. The purpose of creating an AMI in this workshop is to have a standard \u0026ldquo;blueprint\u0026rdquo; for the web server. This blueprint will be used by the Launch Template and Auto Scaling Group in later steps to automatically create identical copies of the server when scaling is needed. üîí Steps to Follow\n1. Select the Source EC2 Instance In the EC2 Dashboard, navigate to Instances. From the list, select the ors-ec2 instance that you have created and will configure in the following steps. Select the ors-ec2 instance as the source 2. Start the Image Creation Process After selecting the instance, click on the Actions menu. Choose Image and templates. Select Create image. Start creating an Image from the Actions menu 3. Configure Information for the AMI On the Create image page, fill in the following information: Image name: ors-ami Image description: ors-ami Other options can be left as default. This ensures the AMI will retain the entire configuration of the original instance. Fill in the configuration information for the AMI 4. Finalize and Check the Status Scroll down and click Create image.\nYou will receive a notification that the AMI creation request has been submitted successfully.\nTo monitor the progress:\nOn the left menu, under the Images section, select AMIs. You will see the ors-ami AMI in a pending state. This process may take a few minutes. Please wait until the Status column changes to Available. Check that the AMI status has changed to Available Excellent! You have successfully created a complete server blueprint. Any EC2 instance created from this AMI will have everything you\u0026rsquo;ve installed, ready to serve users immediately.\n"
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.7-createlaunchtemplate/",
	"title": "Create Launch Template",
	"tags": [],
	"description": "",
	"content": "Create a Launch Template ‚ÑπÔ∏è Objective\nA Launch Template acts as a detailed \u0026ldquo;blueprint\u0026rdquo; for launching an EC2 instance. It stores all necessary configuration parameters such as the AMI, instance type, key pair, and security group. Our goal is to create a Launch Template that uses the web server\u0026rsquo;s AMI (ors-ami) created in the previous step. The Auto Scaling Group will rely on this blueprint to automatically launch new instances consistently and accurately. üîí Steps to Follow\n1. Access Launch Templates From the EC2 Dashboard, on the left menu, scroll down to the Instances section and select Launch Templates. Click on Create launch template. Start creating a Launch Template 2. Configure Basic Information Launch template name: ors-launch-template Template version description: Launch template for Online Restaurant System servers Enter basic information for the Launch Template 3. Select AMI (Amazon Machine Image) In the Application and OS Images (Amazon Machine Image) section, select the My AMIs tab. Select Owned by me and you will see the ors-ami AMI created in the previous step. Select it. Select the created ors-ami AMI 4. Select Instance Type and Key Pair Instance type: Select t2.micro. Key pair (login): Select ors-keypair from the dropdown list. Select Instance Type and Key Pair 5. Configure Network Settings In the Network settings section, we do not need to select a Subnet, as the Auto Scaling Group will decide this automatically. However, we do need to specify the Security Group. Security groups: Choose Select existing security group. From the Common security groups list, select ors-sg. Configure the Security Group for the Launch Template 6. Finalize and Review the Launch Template Review all the configured information in the Summary panel on the right. Scroll down and click Create launch template. Complete the Launch Template creation After successful creation, click View launch templates to review the \u0026ldquo;blueprint\u0026rdquo; you just created in the list. View the Launch Template in the list You now have a complete blueprint. Whenever the system needs a new web server, it can simply use this template to create a perfect copy.\n"
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.8-createtargetgroup/",
	"title": "Create Target Group",
	"tags": [],
	"description": "",
	"content": "Create a Target Group ‚ÑπÔ∏è Objective\nA Target Group is used to group together EC2 instances that the Application Load Balancer (ALB) will route traffic to. The ALB also uses the Target Group to perform Health Checks, ensuring that it only sends requests to instances that are operating normally. We will create a Target Group to manage all the web servers for the restaurant project. üîí Steps to Follow\n1. Access Target Groups From the EC2 Dashboard, on the left menu, scroll down to the Load Balancing section and select Target Groups. Click on Create target group. Start creating a Target Group 2. Choose a Target Type In the Choose a target type step, select Instances, as we want the Load Balancer to route traffic to EC2 instances. Click Next. Select Instances as the Target Type 3. Configure Details for the Target Group Target group name: ors-target-group Protocol - Port: Select HTTP and enter 5000. This is the port our Node.js backend application will be listening on. VPC: Select ors-vpc. Health checks: Health check protocol: HTTP Health check path: /health. What is a Health Check Path? This is a special endpoint that you need to create in your backend code. The Application Load Balancer will continuously send requests to this /health path. If it receives a successful response (HTTP 200 OK), it will consider the instance \u0026ldquo;healthy\u0026rdquo; and continue sending user traffic to it. If not, it will temporarily stop sending traffic to allow the instance to recover.\nEnter the configuration details for the Target Group 4. Register Initial Targets In this step, we will register the manually created ors-ec2 instance into the Target Group. In the Available instances table, select ors-ec2. Click on Include as pending below. This action will add the instance to the pending list to be registered with the group. Why register an initial instance? This helps us verify that the Load Balancer and Target Group are working correctly right after configuration. Instances created later will be automatically registered into this Target Group by the Auto Scaling Group.\nRegister the ors-ec2 instance into the Target Group 5. Finalize and Review Scroll down and click Create target group. After successful creation, you will be taken to the details page of the Target Group. Initially, the Health status of the instance might be initial or unhealthy. Please wait a few minutes for the Load Balancer to perform its health checks, and the status will change to healthy. Target Group created successfully, checking the status "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.9-createalb/",
	"title": "Create Application Load Balancer (ALB)",
	"tags": [],
	"description": "",
	"content": "Create an Application Load Balancer (ALB) ‚ÑπÔ∏è Objective\nThe Application Load Balancer (ALB) acts as the single point of contact for clients and distributes incoming application traffic to the backend servers. By placing the ALB in Public Subnets across multiple Availability Zones (AZs), we ensure the application has High Availability. If one AZ experiences an issue, the ALB will automatically redirect traffic to the servers in the remaining AZ. The ALB will listen for incoming requests and forward them to the Target Group (ors-target-group) that we created in the previous step. üîí Steps to Follow\n1. Start Creating the Load Balancer From the EC2 Dashboard, on the left menu, scroll down to the Load Balancing section and select Load Balancers. Click on Create load balancer. Start creating a Load Balancer 2. Choose the Load Balancer Type Since our application operates at the application layer (HTTP/HTTPS), select Application Load Balancer by clicking Create. Choose Application Load Balancer 3. Configure Basic Information Load balancer name: ors-alb Scheme: Internet-facing (Because this ALB will receive traffic directly from the Internet). IP address type: IPv4 Enter basic configuration information for the ALB 4. Configure Network Mapping This is a crucial step to ensure the ALB operates across multiple AZs and is accessible from the Internet. VPC: Select ors-vpc. Mappings: Select both Availability Zones that we are using. For each AZ, choose the corresponding Public Subnet (e.g., subnet-public1 for ap-southeast-1a and subnet-public2 for ap-southeast-1b). Select the VPC and Public Subnets across both AZs 5. Configure Security Group In the Security groups section, keep the default Security Group selected. From the dropdown list, select the Security Group created specifically for the Web Server: ors-sg. Select the ors-sg Security Group for the ALB 6. Configure Listeners and Routing This is where we define how the ALB handles incoming requests. Listener: Keep HTTP and Port 80 as is. Default action: From the dropdown list, select the ors-target-group created in the previous step. This action instructs the ALB to forward all traffic from port 80 to this Target Group. Configure the Listener and forward to the Target Group 7. Finalize, Check Status, and Test Access Review the information in the Summary section and click Create load balancer. After successful creation, click View load balancer. Note: The process of provisioning a Load Balancer will take a few minutes. Its state will change from provisioning to active. Please be patient.\nWait for the ALB to become Active Once the ALB is active, select it and copy the DNS name from the Details tab. Copy the DNS name of the ALB After you connect to the Backend and upload the project, you will see the result of the next step. Paste this DNS name into your browser. If everything is configured correctly and your backend application is running on the ors-ec2 instance, you will see the welcome message from the API: Welcome to Dining Verse Backend API! "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.10-createasg/",
	"title": "Create Auto Scaling Group (ASG)",
	"tags": [],
	"description": "",
	"content": "Create an Auto Scaling Group (ASG) ‚ÑπÔ∏è Objective\nAn Auto Scaling Group (ASG) is the heart of a flexible architecture on AWS. Its job is to automatically adjust the number of EC2 instances to meet traffic demands. When traffic increases, the ASG will automatically add new instances (Scale Out). When traffic decreases, it will remove unneeded instances (Scale In) to save costs. We will configure an ASG to use the Launch Template (ors-launch-template) to know how to create an instance, and attach it to the Load Balancer (via the Target Group) to know when to take action. üîí Steps to Follow\n1. Start Creating the Auto Scaling Group From the EC2 Dashboard, on the left menu, scroll to the bottom and select Auto Scaling Groups. Click on Create Auto Scaling group. Start creating an Auto Scaling Group 2. Choose Launch Template and Name the Group Auto Scaling group name: ors-asg Launch template: Select ors-launch-template from the list. After selecting, click Next. Name the group and select the Launch Template 3. Configure Network VPC: Select ors-vpc. Availability Zones and subnets: Select both Public Subnets that we have. The ASG will use these subnets to launch new instances, ensuring they are evenly distributed across two AZs for high availability. Click Next. Configure the VPC and Public Subnets 4. Integrate with the Load Balancer Select Attach to an existing load balancer. Choose Choose from your load balancer target groups. From the dropdown list, select ors-target-group. Click Next. Attach the ASG to the existing Target Group 5. Configure Group Size and Scaling Policies Group size:\nDesired capacity: 1 (The desired number of instances when the ASG is created). Minimum capacity: 1 (Always maintain at least 1 instance). Maximum capacity: 2 (Allow a maximum of 2 instances to be created). Scaling policies:\nSelect Target tracking scaling policy. Scaling policy name: Target Tracking Policy Metric type: Application Load Balancer request count per target. Target value: 30. How does this policy work? You are instructing the ASG: \u0026ldquo;Monitor the average number of requests that each EC2 instance is handling. If this number exceeds 30 requests/minute, automatically create a new instance (up to a maximum of 2) to share the load. Conversely, if it is lower than 30, reduce the number of instances (down to a minimum of 1) to save money.\u0026rdquo;\nConfigure group size and Scaling policies Click Next until you reach the Review page. 6. Review and Finalize Review all the configured information on the Review page. Scroll to the bottom and click Create Auto Scaling group. 7. Check the Result After creation, the ASG will appear in the list. Select ors-asg and switch to the Instance management tab. You will see the ASG is in the process of launching a new instance to meet the Desired capacity of 1. Please wait until the instance\u0026rsquo;s Lifecycle is InService. This indicates that the instance is ready and has been successfully registered with the Target Group. Check the instance managed by the ASG "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.11-creates3/",
	"title": "Create S3 Bucket for Frontend",
	"tags": [],
	"description": "",
	"content": "Create an S3 Bucket to Store the Frontend ‚ÑπÔ∏è Objective\nAmazon S3 (Simple Storage Service) is an object storage service that offers scalability, high durability, and low cost. We will use S3 to store all the static files of our frontend application (HTML, CSS, JavaScript, images). Afterward, we will configure this bucket to function as a Static Website Hosting server. üîí Steps to Follow\n1. Start Creating the S3 Bucket In the AWS Management Console, search for and select the S3 service. Click on Create bucket. Start creating an S3 Bucket 2. Configure the Bucket Bucket name: ors-fe S3 bucket names are globally unique. If the name `ors-fe` is already in use, you will need to add characters or numbers to make it unique (e.g., `ors-fe-haminhtri-0309`).\rAWS Region: Choose the region you are working in.\nBlock Public Access settings for this bucket:\nCheck the box for Block all public access. Block public access for the bucket Bucket Versioning: Select Enable. Scroll down and click Create bucket. 3. Upload Frontend Files to the Bucket After the bucket is created successfully, go into the ors-fe bucket. Click Upload and upload all the files and folders of your frontend project. Upload Frontend files to S3 4. Configure Static Website Hosting In the ors-fe bucket, switch to the Properties tab. Scroll to the bottom to the Static website hosting section and click Edit. Select Enable. Index document: index.html Click Save changes. Enable and configure Static Website Hosting "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.12-createcloudfrontbe/",
	"title": "Create CloudFront for Backend (ALB)",
	"tags": [],
	"description": "",
	"content": "Create a CloudFront Distribution for the Backend ‚ÑπÔ∏è Objective\nAmazon CloudFront is a Content Delivery Network (CDN) service that helps speed up and secure web applications. In this step, we will create a CloudFront distribution to act as the public \u0026ldquo;gateway\u0026rdquo; for our backend API, instead of allowing users to access the ALB directly. Key Benefits: HTTPS: CloudFront will provide a secure HTTPS endpoint for users. It will communicate with the ALB over HTTP within the AWS internal network, simplifying SSL certificate management. Performance: CloudFront brings your API closer to users through its global network of Edge Locations, reducing latency. Security: It provides an additional layer of protection, hiding the ALB\u0026rsquo;s actual address, and can be integrated with AWS WAF (Web Application Firewall) later. üîí Steps to Follow\n1. Start Creating the Distribution From the AWS Management Console, search for and select the CloudFront service. Click on Create a CloudFront distribution. Start creating a CloudFront Distribution 2. Configure the Origin Origin domain: Click in the box and select the DNS name of the Application Load Balancer ors-alb from the dropdown list. Protocol: Select HTTP only. HTTP port: Leave the default as 80. How it works: User --(HTTPS)--\u0026gt; CloudFront --(HTTP, port 80)--\u0026gt; ALB. CloudFront will handle the secure HTTPS connection, and then \u0026ldquo;talk\u0026rdquo; to the ALB using regular HTTP.\nConfigure the Origin as the Application Load Balancer 3. Configure the Default Cache Behavior This is the most critical configuration part to ensure the API works correctly. In the Behaviors tab, select Default (*) and click Edit. Cache policy: Select CachingDisabled. This is very important because we do not want CloudFront to cache API responses (which are dynamic and change frequently). Origin request policy - optional: Select AllViewer. This policy forwards all information from the user (headers, query strings, cookies) to the ALB, ensuring the backend receives all the data it needs to process requests. Web Application Firewall (WAF): Select Do not enable security protections for the purpose of this workshop. Click Save changes. Configure the Cache Behavior for the API 4. Finalize, Deploy, and Test Scroll to the bottom of the page and click Create distribution. The process of deploying a new distribution across CloudFront\u0026rsquo;s entire network can take 5 to 15 minutes. You will see the status as Deploying. Wait for CloudFront to finish deploying When the status changes to show a Last modified date, copy the Distribution domain name (e.g., d12345abcdef.cloudfront.net). Copy the Distribution Domain Name Paste this domain name into your browser. The response should be identical to when you accessed the ALB\u0026rsquo;s DNS: Welcome to Dining Verse Backend API!. This confirms that CloudFront has been successfully configured to act as a proxy for your ALB. "
},
{
	"uri": "http://localhost:1313/2-prerequiste/2.13-createcloudfrontfe/",
	"title": "Create CloudFront for Frontend (S3)",
	"tags": [],
	"description": "",
	"content": "Create a CloudFront Distribution for the Frontend (S3) ‚ÑπÔ∏è Objective\nCreate a second CloudFront Distribution, this time specifically for serving the static frontend files from the S3 bucket. Speed up page load times: CloudFront will cache the frontend files (HTML, CSS, JS, images) at its global Edge Locations, allowing users everywhere to access the website with the lowest possible latency. Enhance security: We will configure an Origin Access Identity (OAI). An OAI is a special virtual user created by CloudFront. We will grant this OAI permission to read files in our S3 bucket and then lock the bucket down, preventing any other public access. This ensures that all users must go through CloudFront to view your website. üîí Steps to Follow\n1. Start Creating the Distribution In the AWS Management Console, return to the CloudFront service. Click on Create distribution. Start creating a new CloudFront Distribution 2. Configure the Origin Origin domain: Click in this box and select your S3 bucket from the list: ors-fe.s3.ap-southeast-1.amazonaws.com. Origin access: This is the most critical security configuration step. Select Legacy access identities. Origin access identity: Click on Create new OAI. Leave the default name and click Create. Bucket policy: Select Yes, update the bucket policy. This action will automatically add a policy to your S3 bucket, granting the newly created OAI permission to read the objects. Configure the Origin as an S3 Bucket and create an OAI 3. Configure Remaining Settings Web Application Firewall (WAF): Select Do not enable security protections. Settings - Price Class: Select Use North America, Europe, Asia, Middle East, and Africa to optimize cost and performance. Settings - Default root object: Type index.html. This is a mandatory setting. It tells CloudFront which file to return when a user accesses the root domain (e.g., `https://d...cloudfront.net/`) without specifying a particular file.\rSet up additional settings 4. Finalize, Deploy, and Test Scroll to the bottom and click Create distribution. As before, the deployment process will take a few minutes. Please wait until the status is no longer Deploying. Copy the Distribution domain name value. Copy the Domain Name of the Frontend Distribution Paste this domain name into your browser. You will see your frontend application load successfully, quickly, and securely through the CloudFront network! "
},
{
	"uri": "http://localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]